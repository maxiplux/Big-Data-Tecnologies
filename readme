Be Sure that Hbase is running
0A sudo service hbase-regionserver start
0B sudo service hbase-master start
Install kafka and run the next command
0C kafka-console-producer --broker-list localhost:9092 --topic tweets
Install conda and run the next commands

1 source activate /home/cloudera/anaconda3/envs/py351
1.1 install al libraries using pip
1.2  pip install -r requirements.txt
1.3 ( If like run you need go to twitter and make your own KEYS account access and install on
confi.py)

2 python aspark.py
2 python atwitter.py


Install on hive the table table.hive.

if you like run the graphis run the next command
juppyter notebook and find Graph 1.ipynb and QueryHiveToVisualized.ipynb

#/usr/lib/spark/conf/spark-defaults.conf
#spark.driver.extraClassPath /home/cloudera/bigdataml/spark-sql-kafka-0-10_2.11-2.1.0.cloudera1.jar
#spark.executor.extraClassPath /home/cloudera/bigdataml/spark-sql-kafka-0-10_2.11-2.1.0.cloudera1.jar
